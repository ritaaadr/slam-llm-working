[2023-12-17 21:51:59][root][INFO] - train_config: train_config(model_name='asr', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, batching_strategy='custom', context_length=4096, gradient_accumulation_steps=1, num_epochs=100, num_workers_dataloader=1, lr=1e-05, weight_decay=0.0, gamma=0.85, seed=42, use_fp16=False, mixed_precision=True, val_batch_size=4, peft_method='lora', use_peft=False, output_dir='/nfs/maziyang.mzy/exps/llama-2-hf-finetune-asr-ds5-proj2048', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, dist_checkpoint_root_folder='PATH/to/save/FSDP/model', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, log_file='/root/SLAM-LLM/log/test.log', run_test_during_validation=True, run_test_during_validation_file='/cpfs01/shared/Group-speech/beinian.lzr/data/open_data/librispeech_audio/audio/se_librispeech_1001-134707-0000.wav', run_test_during_validation_prompt='<|ASR|>', freeze_llm=True, freeze_encoder=True, log_interval=5)
[2023-12-17 21:51:59][root][INFO] - fsdp_config: fsdp_config(mixed_precision=True, use_fp16=False, sharding_strategy=<ShardingStrategy.NO_SHARD: 3>, checkpoint_type=<StateDictType.SHARDED_STATE_DICT: 3>, fsdp_activation_checkpointing=True, fsdp_cpu_offload=False, pure_bf16=False, optimizer='AdamW')
[2023-12-17 21:51:59][root][INFO] - model_config: model_config(llm_name='llama-2-7b-hf', llm_path='/nfs/zhifu.gzf/ckpt/Llama-2-7b-hf', encoder_name='whisper', encoder_ds_rate=2, encoder_path='/nfs/zhifu.gzf/ckpt/Whisper/large-v2.pt', encoder_projector='linear', encoder_projector_ds_rate=5, DMODEL=512, FRONTEND_DMODEL=1024, TX_ATTENTION_HEADS=8, TX_NUM_LAYERS=6, PE_MAX_LENGTH=500, AUDIO_FEATURE_SIZE=1024, VIDEO_FEATURE_SIZE=2048, TX_FEEDFORWARD_DIM=2048, TX_DROPOUT=0.1, CHAR_NUM_CLASSES=40, WORD_NUM_CLASSES=500, FRAME_LENGTH=29, MOCO_FRONTEND_FILE='/nfs/yangguanrou.ygr/AVSR/pretrain_model/moco_frontend.pt', WAV2VEC_FILE='/nfs/yangguanrou.ygr/AVSR/pretrain_model/wav2vec_vox_new.pt', MAIN_REQ_INPUT_LENGTH=80, modal='AV', TRAIN_LRS3_MODEL_FILE='/nfs/yangguanrou.ygr/AVSR/train-step_0108-wer_0.058.ckpt', TRAINED_AO_FILE='/nfs/yangguanrou.ygr/AVSR/check/train-step_0604-wer_0.054.ckpt', TRAINED_VO_FILE='/nfs/yangguanrou.ygr/AVSR/check/train-step_1191-wer_0.674.ckpt')
[2023-12-17 21:52:18][llama_recipes.utils.train_utils][INFO] - --> Module whisper
[2023-12-17 21:52:18][llama_recipes.utils.train_utils][INFO] - --> whisper has 634.86464 Million params

[2023-12-17 21:52:18][llama_recipes.utils.train_utils][INFO] - --> Module whisper
[2023-12-17 21:52:18][llama_recipes.utils.train_utils][INFO] - --> whisper has 0.0 Million params

[2023-12-17 21:53:22][llama_recipes.utils.train_utils][INFO] - --> Module llama-2-7b-hf
[2023-12-17 21:53:22][llama_recipes.utils.train_utils][INFO] - --> llama-2-7b-hf has 6738.415616 Million params

[2023-12-17 21:53:22][llama_recipes.utils.train_utils][INFO] - --> Module llama-2-7b-hf
[2023-12-17 21:53:22][llama_recipes.utils.train_utils][INFO] - --> llama-2-7b-hf has 0.0 Million params

[2023-12-17 21:53:22][llama_recipes.utils.train_utils][INFO] - --> Module linear
[2023-12-17 21:53:22][llama_recipes.utils.train_utils][INFO] - --> linear has 21.501952 Million params

[2023-12-17 21:53:22][llama_recipes.utils.train_utils][INFO] - --> Model asr
[2023-12-17 21:53:22][llama_recipes.utils.train_utils][INFO] - --> asr has 21.501952 Million params

[2023-12-17 21:53:27][root][INFO] - dataset_config: custom_dataset(dataset='custom_dataset', file='src/llama_recipes/datasets/speech_dataset.py:get_audio_dataset', train_split='train', test_split='validation', data_path=None, max_words=None, train_data_path='/nfs/beinian.lzr/workspace/datasets/speech_llm/train_dataset/data_wav_json/asr/librispeech_train_960h_wav_speech_llm_train_data.json', val_data_path='/nfs/beinian.lzr/workspace/datasets/data/16k/opendata/librispeech/dev_other/librispeech_dev_other.jsonl', max_mel=None, fix_length_audio=-1)
[2023-12-17 21:53:35][root][INFO] - --> Training Set Length = 280879
[2023-12-17 21:53:35][root][INFO] - --> Validation Set Length = 2864
[2023-12-17 21:53:35][llama_recipes.utils.config_utils][INFO] - Using batching strategy: custom
[2023-12-17 21:53:35][llama_recipes.utils.config_utils][INFO] - Using batching strategy: custom
