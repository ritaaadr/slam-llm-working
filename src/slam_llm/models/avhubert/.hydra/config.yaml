model_config:
  llm_name: vicuna-7b-v1.5
  llm_path: /nfs/maziyang.mzy/models/vicuna-7b-v1.5
  llm_dim: 4096
  encoder_name: av_hubert
  encoder_ds_rate: 2
  encoder_path: /nfs/yangguanrou.ygr/av_hubert/large_vox_433h.pt
  encoder_dim: 1024
  encoder_projector: linear
  encoder_projector_ds_rate: 5
  DMODEL: 512
  FRONTEND_DMODEL: 1024
  TX_ATTENTION_HEADS: 8
  TX_NUM_LAYERS: 6
  PE_MAX_LENGTH: 500
  AUDIO_FEATURE_SIZE: 1024
  VIDEO_FEATURE_SIZE: 2048
  TX_FEEDFORWARD_DIM: 2048
  TX_DROPOUT: 0.1
  CHAR_NUM_CLASSES: 40
  WORD_NUM_CLASSES: 500
  FRAME_LENGTH: 29
  MOCO_FRONTEND_FILE: /nfs/yangguanrou.ygr/AVSR/pretrain_model/moco_frontend.pt
  WAV2VEC_FILE: /nfs/yangguanrou.ygr/AVSR/pretrain_model/wav2vec_vox_new.pt
  MAIN_REQ_INPUT_LENGTH: int = 80
  modal: VO
  TRAIN_LRS3_MODEL_FILE: /nfs/yangguanrou.ygr/AVSR/train-step_0108-wer_0.058.ckpt
  TRAINED_AO_FILE: /nfs/yangguanrou.ygr/AVSR/check/train-step_0604-wer_0.054.ckpt
  TRAINED_VO_FILE: /nfs/yangguanrou.ygr/AVSR/check/train-step_1191-wer_0.674.ckpt
train_config:
  model_name: asr
  enable_ddp: false
  enable_fsdp: false
  low_cpu_fsdp: false
  run_validation: true
  batch_size_training: 4
  batching_strategy: custom
  context_length: 4096
  gradient_accumulation_steps: 1
  num_epochs: 10
  num_workers_dataloader: 0
  warmup_steps: 1000
  total_steps: 100000
  validation_interval: 10
  lr: 0.0001
  weight_decay: 0.0
  gamma: 0.85
  seed: 42
  use_fp16: false
  mixed_precision: true
  val_batch_size: 4
  use_peft: false
  peft_config:
    peft_method: lora
    r: 8
    lora_alpha: 32
    target_modules:
    - q_proj
    - v_proj
    bias: none
    task_type: CAUSAL_LM
    lora_dropout: 0.05
    inference_mode: false
  output_dir: /nfs/yangguanrou.ygr/vicuna-7b-v1.5-large_vox_433h-0129
  freeze_layers: false
  num_freeze_layers: 1
  quantization: false
  one_gpu: false
  save_model: true
  dist_checkpoint_root_folder: PATH/to/save/FSDP/model
  dist_checkpoint_folder: fine-tuned
  save_optimizer: false
  use_fast_kernels: false
  run_test_during_validation: false
  run_test_during_validation_file: test.wav
  run_test_during_validation_prompt: <|ASR|>
  freeze_llm: true
  freeze_encoder: true
dataset_config:
  dataset: avsr_dataset
  file: src/llama_recipes/datasets/avsr_dataset.py:get_audio_dataset
  train_split: train
  test_split: val
  data_path: /nfs/yangguanrou.ygr/
  h5file: /nfs/yangguanrou.ygr/LRS3/LRS3.h5
  noiseFile: /nfs/yangguanrou.ygr/AVSR/LRS3/Noise.h5
  noiseProb: 0.0
  noiseSNR: 5
  stepSize: 16384
  modal: VO
  pretrain_subset: LRS3/pretrain.txt
  train_subset: LRS3/train.txt
  valid_subset: LRS3/val.txt
  test_subset: LRS3/test.txt
  reqInpLen: 80
  fix_length_audio: -1
  inference_mode: false
  charToIx: x
fsdp_config:
  mixed_precision: true
  use_fp16: false
  sharding_strategy: NO_SHARD
  checkpoint_type: SHARDED_STATE_DICT
  fsdp_activation_checkpointing: true
  fsdp_cpu_offload: false
  pure_bf16: false
  optimizer: AdamW
log_config:
  use_wandb: false
  wandb_dir: /root/test_wandb
  wandb_entity_name: project_name
  wandb_project_name: project_name
  wandb_exp_name: exp_name
  log_file: /root/test.log
  log_interval: 5
metric: acc
